{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Nhatty1788/NatnaelMolago_DTSC3020_Fall2025/blob/main/assignment6_nsm0128.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H_de5Eq4u-tR"
      },
      "source": [
        "# Assignment 6 (4 points) — Web Scraping\n",
        "\n",
        "In this assignment you will complete **two questions**. The **deadline is posted on Canvas**.\n"
      ],
      "id": "H_de5Eq4u-tR"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4PHwamZMu-tX"
      },
      "source": [
        "## Assignment Guide (Read Me First)\n",
        "\n",
        "- This notebook provides an **Install Required Libraries** cell and a **Common Imports & Polite Headers** cell. Run them first.\n",
        "- Each question includes a **skeleton**. The skeleton is **not** a solution; it is a lightweight scaffold you may reuse.\n",
        "- Under each skeleton you will find a **“Write your answer here”** code cell. Implement your scraping, cleaning, and saving logic there.\n",
        "- When your code is complete, run the **Runner** cell to print a Top‑15 preview and save the CSV.\n",
        "- Expected outputs:\n",
        "  - **Q1:** `data_q1.csv` + Top‑15 sorted by the specified numeric column.\n",
        "  - **Q2:** `data_q2.csv` + Top‑15 sorted by `points`.\n"
      ],
      "id": "4PHwamZMu-tX"
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "I7DLq9nEu-tZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bc3acc2f-d412-4225-8477-9027544dceb0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dependencies installed.\n"
          ]
        }
      ],
      "source": [
        " #Install Required Libraries\n",
        "!pip -q install requests beautifulsoup4 lxml pandas\n",
        "print(\"Dependencies installed.\")\n"
      ],
      "id": "I7DLq9nEu-tZ"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ug_A9RuPu-tb"
      },
      "source": [
        "### 2) Common Imports & Polite Headers"
      ],
      "id": "ug_A9RuPu-tb"
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "Ov8pXh65u-tc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ee914ec6-ee59-4e51-c3fb-737aee6dd576"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Common helpers loaded.\n"
          ]
        }
      ],
      "source": [
        "# Common Imports & Polite Headers\n",
        "import re, sys, pandas as pd, requests\n",
        "from bs4 import BeautifulSoup\n",
        "HEADERS = {\"User-Agent\": (\n",
        "    \"Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 \"\n",
        "    \"(KHTML, like Gecko) Chrome/122.0 Safari/537.36\")}\n",
        "def fetch_html(url: str, timeout: int = 20) -> str:\n",
        "    r = requests.get(url, headers=HEADERS, timeout=timeout)\n",
        "    r.raise_for_status()\n",
        "    return r.text\n",
        "def flatten_headers(df: pd.DataFrame) -> pd.DataFrame:\n",
        "    if isinstance(df.columns, pd.MultiIndex):\n",
        "        df.columns = [\" \".join([str(x) for x in tup if str(x)!=\"nan\"]).strip()\n",
        "                      for tup in df.columns.values]\n",
        "    else:\n",
        "        df.columns = [str(c).strip() for c in df.columns]\n",
        "    return df\n",
        "print(\"Common helpers loaded.\")\n"
      ],
      "id": "Ov8pXh65u-tc"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "km0GO7zzu-td"
      },
      "source": [
        "## Question 1 — IBAN Country Codes (table)\n",
        "**URL:** https://www.iban.com/country-codes  \n",
        "**Extract at least:** `Country`, `Alpha-2`, `Alpha-3`, `Numeric` (≥4 cols; you may add more)  \n",
        "**Clean:** trim spaces; `Alpha-2/Alpha-3` → **UPPERCASE**; `Numeric` → **int** (nullable OK)  \n",
        "**Output:** write **`data_q1.csv`** and **print a Top-15** sorted by `Numeric` (desc, no charts)  \n",
        "**Deliverables:** notebook + `data_q1.csv` + short `README.md` (URL, steps, 1 limitation)\n",
        "\n",
        "**Tip:** You can use `pandas.read_html(html)` to read tables and then pick one with ≥3 columns.\n"
      ],
      "id": "km0GO7zzu-td"
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "q1_skeleton"
      },
      "outputs": [],
      "source": [
        "# --- Q1 Skeleton (fill the TODOs) ---\n",
        "def q1_read_table(html: str) -> pd.DataFrame:\n",
        "    \"\"\"Return the first table with >= 3 columns from the HTML.\n",
        "    TODO: implement with pd.read_html(html), pick a reasonable table, then flatten headers.\n",
        "    \"\"\"\n",
        "    # Load all tables from the page\n",
        "    tables = pd.read_html(html)\n",
        "\n",
        "    # Return first table with >= 3 columns and flatten headers\n",
        "    for t in tables:\n",
        "        if t.shape[1] >= 3:\n",
        "            return flatten_headers(t)\n",
        "\n",
        "    # If no valid table found, return empty dataframe\n",
        "    return pd.DataFrame()\n",
        "    raise NotImplementedError(\"TODO: implement q1_read_table\")\n",
        "\n",
        "def q1_clean(df: pd.DataFrame) -> pd.DataFrame:\n",
        "    \"\"\"Clean columns: strip, UPPER Alpha-2/Alpha-3, cast Numeric to int (nullable), drop invalids.\n",
        "    TODO: implement cleaning steps.\n",
        "    \"\"\"\n",
        "    # Standardize column names (handles space/underscore changes)\n",
        "    df.columns = [c.strip().replace(\"_\", \" \") for c in df.columns]\n",
        "\n",
        "    # strip whitespace\n",
        "    df = df.applymap(lambda x: x.strip() if isinstance(x, str) else x)\n",
        "\n",
        "    # uppercase codes\n",
        "    if \"Alpha-2 code\" in df.columns:\n",
        "        df[\"Alpha-2 code\"] = df[\"Alpha-2 code\"].str.upper()\n",
        "    if \"Alpha-3 code\" in df.columns:\n",
        "        df[\"Alpha-3 code\"] = df[\"Alpha-3 code\"].str.upper()\n",
        "\n",
        "    # numeric conversion\n",
        "    if \"Numeric code\" in df.columns:\n",
        "        df[\"Numeric code\"] = pd.to_numeric(df[\"Numeric code\"], errors=\"coerce\").astype(\"Int64\")\n",
        "\n",
        "    # drop incomplete rows (only if column exists)\n",
        "    cols = [c for c in [\"Country\", \"Alpha-2 code\", \"Alpha-3 code\"] if c in df.columns]\n",
        "    df = df.dropna(subset=cols)\n",
        "\n",
        "    return df\n",
        "    raise NotImplementedError(\"TODO: implement q1_clean\")\n",
        "\n",
        "\n",
        "def q1_sort_top(df: pd.DataFrame, top: int = 15) -> pd.DataFrame:\n",
        "    \"\"\"Sort descending by Numeric and return Top-N.\n",
        "    TODO: implement.\n",
        "    \"\"\"\n",
        "    # Find the numeric column regardless of underscore/capitalization changes\n",
        "    num_col = None\n",
        "    for c in df.columns:\n",
        "        if c.lower().replace(\"_\", \" \").strip() == \"numeric code\":\n",
        "            num_col = c\n",
        "            break\n",
        "\n",
        "    if num_col is None:\n",
        "        # If no numeric column found, return top rows as-is\n",
        "        return df.head(top)\n",
        "\n",
        "    # Sort by detected numeric column\n",
        "    return df.sort_values(num_col, ascending=False).head(top)\n",
        "\n",
        "    raise NotImplementedError(\"TODO: implement q1_sort_top\")\n"
      ],
      "id": "q1_skeleton"
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "q1_skeleton_answer",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "27ce7ffd-8a9d-49fa-a546-5a77b426bef6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                Country Alpha-2 code Alpha-3 code  Numeric\n",
            "0           Afghanistan           AF          AFG        4\n",
            "1         Åland Islands           AX          ALA      248\n",
            "2               Albania           AL          ALB        8\n",
            "3               Algeria           DZ          DZA       12\n",
            "4        American Samoa           AS          ASM       16\n",
            "5               Andorra           AD          AND       20\n",
            "6                Angola           AO          AGO       24\n",
            "7              Anguilla           AI          AIA      660\n",
            "8            Antarctica           AQ          ATA       10\n",
            "9   Antigua and Barbuda           AG          ATG       28\n",
            "10            Argentina           AR          ARG       32\n",
            "11              Armenia           AM          ARM       51\n",
            "12                Aruba           AW          ABW      533\n",
            "13            Australia           AU          AUS       36\n",
            "14              Austria           AT          AUT       40\n"
          ]
        }
      ],
      "source": [
        "import warnings\n",
        "from io import StringIO\n",
        "\n",
        "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
        "\n",
        "\n",
        "url = \"https://www.iban.com/country-codes\"\n",
        "html = fetch_html(url)\n",
        "df_raw = q1_read_table(html)\n",
        "df_clean = q1_clean(df_raw)\n",
        "df_top15 = q1_sort_top(df_clean)\n",
        "\n",
        "print(df_top15)\n",
        "df_clean.to_csv(\"data_q1.csv\", index=False)"
      ],
      "id": "q1_skeleton_answer"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rmefu--_u-tg"
      },
      "source": [
        "## Question 2 — Hacker News (front page)\n",
        "**URL:** https://news.ycombinator.com/  \n",
        "**Extract at least:** `rank`, `title`, `link`, `points`, `comments` (user optional)  \n",
        "**Clean:** cast `points`/`comments`/`rank` → **int** (non-digits → 0), fill missing text fields  \n",
        "**Output:** write **`data_q2.csv`** and **print a Top-15** sorted by `points` (desc, no charts)  \n",
        "**Tip:** Each story is a `.athing` row; details (points/comments/user) are in the next `<tr>` with `.subtext`.\n"
      ],
      "id": "rmefu--_u-tg"
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "q2_skeleton"
      },
      "outputs": [],
      "source": [
        "# --- Q2 Skeleton (fill the TODOs) ---\n",
        "def q2_parse_items(html: str) -> pd.DataFrame:\n",
        "    \"\"\"Parse front page items into DataFrame columns:\n",
        "       rank, title, link, points, comments, user (optional).\n",
        "    TODO: implement with BeautifulSoup on '.athing' and its sibling '.subtext'.\n",
        "    \"\"\"\n",
        "    soup = BeautifulSoup(html, \"lxml\")\n",
        "    items = soup.select(\".athing\")\n",
        "\n",
        "    rows = []\n",
        "    for item in items:\n",
        "        rank_tag = item.select_one(\".rank\")\n",
        "        title_tag = item.select_one(\".titleline a\")\n",
        "\n",
        "        # subtext is in next <tr>\n",
        "        sub = item.find_next_sibling(\"tr\").select_one(\".subtext\")\n",
        "\n",
        "        points = sub.select_one(\".score\") if sub else None\n",
        "        user = sub.select_one(\".hnuser\") if sub else None\n",
        "\n",
        "        # comments link = last <a> in subtext\n",
        "        comments_link = sub.find_all(\"a\")[-1] if sub else None\n",
        "        comments_text = comments_link.text if comments_link else \"\"\n",
        "\n",
        "        rows.append({\n",
        "            \"rank\": rank_tag.text.replace(\".\", \"\") if rank_tag else \"\",\n",
        "            \"title\": title_tag.text if title_tag else \"\",\n",
        "            \"link\": title_tag[\"href\"] if title_tag else \"\",\n",
        "            \"points\": points.text.replace(\" points\", \"\").replace(\" point\", \"\") if points else \"\",\n",
        "            \"comments\": comments_text.replace(\" comments\", \"\").replace(\" comment\", \"\") if comments_text else \"\",\n",
        "            \"user\": user.text if user else \"\"\n",
        "        })\n",
        "\n",
        "    df = pd.DataFrame(rows)\n",
        "    return df\n",
        "    raise NotImplementedError(\"TODO: implement q2_parse_items\")\n",
        "\n",
        "\n",
        "def q2_clean(df: pd.DataFrame) -> pd.DataFrame:\n",
        "    \"\"\"Clean numeric fields and fill missing values.\n",
        "    TODO: cast points/comments/rank to int (non-digits -> 0). Fill text fields.\n",
        "    \"\"\"\n",
        "    # numeric fields → int or 0\n",
        "    for col in [\"rank\", \"points\", \"comments\"]:\n",
        "        df[col] = pd.to_numeric(df[col], errors=\"coerce\").fillna(0).astype(int)\n",
        "\n",
        "    # fill blank strings\n",
        "    for col in [\"title\", \"link\", \"user\"]:\n",
        "        df[col] = df[col].fillna(\"\").astype(str)\n",
        "\n",
        "    return df\n",
        "    raise NotImplementedError(\"TODO: implement q2_clean\")\n",
        "\n",
        "\n",
        "def q2_sort_top(df: pd.DataFrame, top: int = 15) -> pd.DataFrame:\n",
        "    \"\"\"Sort by points desc and return Top-N. TODO: implement.\"\"\"\n",
        "    return df.sort_values(\"points\", ascending=False).head(top)\n",
        "    raise NotImplementedError(\"TODO: implement q2_sort_top\")\n"
      ],
      "id": "q2_skeleton"
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "q2_skeleton_answer",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b75787f6-bdb6-4bc4-ef94-341527b5c432"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    rank                                              title  \\\n",
            "10    11                           Leaving Meta and PyTorch   \n",
            "23    24  Meta projected 10% of 2024 revenue came from s...   \n",
            "13    14                                    A Fond Farewell   \n",
            "29    30                              Game design is simple   \n",
            "0      1  Vodafone Germany is killing the open internet ...   \n",
            "12    13  Denmark's government aims to ban access to soc...   \n",
            "7      8                                       I Love OCaml   \n",
            "1      2  Rockstar employee shares account of the compan...   \n",
            "21    22  OpenMW 0.50.0 Released – open-source Morrowind...   \n",
            "27    28    A.I. and Social Media Contribute to 'Brain Rot'   \n",
            "5      6                       Gmail AI gets more intrusive   \n",
            "26    27             Text case changes the size of QR codes   \n",
            "28    29                 We chose OCaml to write Stategraph   \n",
            "16    17                                     PyTorch Helion   \n",
            "17    18  Toxic Salton Sea dust triggers changes in lung...   \n",
            "\n",
            "                                                 link  points  comments  \\\n",
            "10  https://soumith.ch/blog/2025-11-06-leaving-met...     632         0   \n",
            "23  https://sherwood.news/tech/meta-projected-10-o...     532         0   \n",
            "13  https://www.farmersalmanac.com/fond-farewell-f...     528         0   \n",
            "29  https://www.raphkoster.com/2025/11/03/game-des...     482         0   \n",
            "0   https://coffee.link/vodafone-germany-is-killin...     329         0   \n",
            "12  https://apnews.com/article/denmark-social-medi...     253         0   \n",
            "7     https://mccd.space/posts/ocaml-the-worlds-best/     224         0   \n",
            "1   https://gtaforums.com/topic/1004182-rockstar-g...     222         0   \n",
            "21    https://openmw.org/2025/openmw-0-50-0-released/     221         0   \n",
            "27  https://www.nytimes.com/2025/11/06/technology/...     171         0   \n",
            "5   https://daveverse.org/2025/11/07/gmail-ai-gets...     162         0   \n",
            "26  https://www.johndcook.com/blog/2025/10/31/smal...     141         0   \n",
            "28     https://stategraph.dev/blog/why-we-chose-ocaml     124         0   \n",
            "16                   https://pytorch.org/blog/helion/     116         0   \n",
            "17  https://phys.org/news/2025-10-toxic-salton-sea...      75         0   \n",
            "\n",
            "         user  \n",
            "10   saikatsg  \n",
            "23    donohoe  \n",
            "13     erhuve  \n",
            "29      vrnvu  \n",
            "0    PhilKunz  \n",
            "12       c420  \n",
            "7       art-w  \n",
            "1      mrzool  \n",
            "21   agluszak  \n",
            "27    pretext  \n",
            "5      speckx  \n",
            "26     ibobev  \n",
            "28  lawnchair  \n",
            "16     jarbus  \n",
            "17  PaulHoule  \n"
          ]
        }
      ],
      "source": [
        "# Q2 — Write your answer here\n",
        "\n",
        "url = \"https://news.ycombinator.com/\"\n",
        "html = fetch_html(url)\n",
        "\n",
        "df_raw = q2_parse_items(html)\n",
        "df_clean = q2_clean(df_raw)\n",
        "df_top15 = q2_sort_top(df_clean)\n",
        "\n",
        "print(df_top15)\n",
        "df_clean.to_csv(\"data_q2.csv\", index=False)\n",
        "\n"
      ],
      "id": "q2_skeleton_answer"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}